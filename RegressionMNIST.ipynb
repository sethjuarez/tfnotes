{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Softmax MNIST Regression\n",
    "* Adapted from [TensorFlow-Examples](https://github.com/aymericdamien/TensorFlow-Examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import *\n",
    "\n",
    "# clearing graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "display_epoch = 1\n",
    "logs_path = datetime.now().strftime('./logs/clean_%m-%d_%H_%M_%S')\n",
    "\n",
    "# tf Graph Input\n",
    "# mnist data image of shape 28*28=784\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='InputData')\n",
    "# 0-9 digits recognition => 10 classes\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='LabelData')\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]), name='Weights')\n",
    "b = tf.Variable(tf.zeros([10]), name='Bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model and encapsulating all ops into scopes, making\n",
    "# Tensorboard's Graph visualization more convenient\n",
    "with tf.name_scope('Model'):\n",
    "    # Model\n",
    "    #pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "    pred = tf.matmul(x, W) + b # Softmax\n",
    "with tf.name_scope('Loss'):\n",
    "    # Minimize error using cross entropy\n",
    "    # cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=1))\n",
    "    \n",
    "    # Minimize error with *better* cross entropy\n",
    "    # cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "    \n",
    "    # Minimize error using squared error\n",
    "    # cost = tf.nn.l2_loss(y - pred)\n",
    "    \n",
    "    # Minimize with computed square error\n",
    "    cost = tf.reduce_mean(tf.pow(y - pred, 2))\n",
    "with tf.name_scope('SGD'):\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    acc = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "# Create a summary to monitor accuracy tensor\n",
    "tf.summary.scalar(\"accuracy\", acc)\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.058066755\n",
      "Epoch: 0002 cost= 0.046458825\n",
      "Epoch: 0003 cost= 0.044295555\n",
      "Epoch: 0004 cost= 0.043248489\n",
      "Epoch: 0005 cost= 0.042594659\n",
      "Epoch: 0006 cost= 0.042127270\n",
      "Epoch: 0007 cost= 0.041766623\n",
      "Epoch: 0008 cost= 0.041481314\n",
      "Epoch: 0009 cost= 0.041238637\n",
      "Epoch: 0010 cost= 0.041037733\n",
      "Epoch: 0011 cost= 0.040862047\n",
      "Epoch: 0012 cost= 0.040712288\n",
      "Epoch: 0013 cost= 0.040573301\n",
      "Epoch: 0014 cost= 0.040456315\n",
      "Epoch: 0015 cost= 0.040348871\n",
      "Epoch: 0016 cost= 0.040250906\n",
      "Epoch: 0017 cost= 0.040164304\n",
      "Epoch: 0018 cost= 0.040082074\n",
      "Epoch: 0019 cost= 0.040010998\n",
      "Epoch: 0020 cost= 0.039941753\n",
      "Epoch: 0021 cost= 0.039878743\n",
      "Epoch: 0022 cost= 0.039821497\n",
      "Epoch: 0023 cost= 0.039770016\n",
      "Epoch: 0024 cost= 0.039723357\n",
      "Epoch: 0025 cost= 0.039673411\n",
      "Epoch: 0026 cost= 0.039631341\n",
      "Epoch: 0027 cost= 0.039586781\n",
      "Epoch: 0028 cost= 0.039549920\n",
      "Epoch: 0029 cost= 0.039514472\n",
      "Epoch: 0030 cost= 0.039481705\n",
      "Epoch: 0031 cost= 0.039446467\n",
      "Epoch: 0032 cost= 0.039416965\n",
      "Epoch: 0033 cost= 0.039387265\n",
      "Epoch: 0034 cost= 0.039361317\n",
      "Epoch: 0035 cost= 0.039336004\n",
      "Epoch: 0036 cost= 0.039311885\n",
      "Epoch: 0037 cost= 0.039283645\n",
      "Epoch: 0038 cost= 0.039259603\n",
      "Epoch: 0039 cost= 0.039242439\n",
      "Epoch: 0040 cost= 0.039221940\n",
      "Epoch: 0041 cost= 0.039199996\n",
      "Epoch: 0042 cost= 0.039180192\n",
      "Epoch: 0043 cost= 0.039163669\n",
      "Epoch: 0044 cost= 0.039144097\n",
      "Epoch: 0045 cost= 0.039126469\n",
      "Epoch: 0046 cost= 0.039113015\n",
      "Epoch: 0047 cost= 0.039096417\n",
      "Epoch: 0048 cost= 0.039079464\n",
      "Epoch: 0049 cost= 0.039068670\n",
      "Epoch: 0050 cost= 0.039054224\n",
      "Optimization Finished!\n",
      "Accuracy: 0.8642\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop), cost op (to get loss value)\n",
    "            # and summary nodes\n",
    "            _, c, summary = sess.run([optimizer, cost, merged_summary_op],\n",
    "                                     feed_dict={x: batch_xs, y: batch_ys})\n",
    "            # Write logs at every iteration\n",
    "            summary_writer.add_summary(summary, epoch * total_batch + i)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_epoch == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    # Calculate accuracy\n",
    "    print(\"Accuracy:\", acc.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
